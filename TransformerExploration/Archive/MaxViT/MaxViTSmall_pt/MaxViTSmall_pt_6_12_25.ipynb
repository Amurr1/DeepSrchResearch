{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5705d702-80aa-4600-b12d-64c03cc2c5af",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Notebook Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d8d1b5-8195-48bc-8399-f9dc9ddd76b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4101b74d-2bb5-4923-8964-09bf513fa804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchmetrics\n",
    "import timm\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import random\n",
    "import math\n",
    "\n",
    "from datetime import date\n",
    "import time\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c85d610e-6bdc-4d9b-ae67-78477a10207c",
   "metadata": {},
   "source": [
    "!nvidia-smi\n",
    "\n",
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b952d3c-d707-426e-a19e-1a511b0fa9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_deluxe = '/global/cfs/projectdirs/cosmo/work/users/xhuang/dr10_1/Clean-Samples/TS40_deluxe_clean'\n",
    "data_path = clean_deluxe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d04caf0-3151-4d71-accc-215e0587fb6c",
   "metadata": {},
   "source": [
    " * clean deluxe is our highest quality sample, in the Clean-Samples dir you will find TS40 Baseline, which has more samples, but some positive and negative candidates may not be as clear, or have additional noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b28db5-7a54-40f2-8e76-b5674fe8e12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = np.load(f\"{data_path}/train_x.npy\")\n",
    "ytrain = np.load(f\"{data_path}/train_y.npy\").reshape(-1, 1)\n",
    "\n",
    "xval = np.load(f\"{data_path}/val_x.npy\")\n",
    "yval = np.load(f\"{data_path}/val_y.npy\").reshape(-1, 1)\n",
    "\n",
    "xtrain = np.clip(xtrain, -1, 1)  \n",
    "xval = np.clip(xval, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c164c208-1782-4920-a49c-6d4bbc70ebad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReflectiveAugmentor:\n",
    "    def __init__(self, rotation=True, flip=True, max_angle=180, pad_margin=0.01): # Extra padding beyond what's necessary \n",
    "        self.rotation = rotation\n",
    "        self.flip = flip\n",
    "        self.max_angle = max_angle\n",
    "        self.pad_margin = pad_margin\n",
    "\n",
    "    def __call__(self, image):\n",
    "\n",
    "        if self.flip:\n",
    "            if random.random() > 0.5:\n",
    "                image = TF.hflip(image)\n",
    "            if random.random() > 0.5:\n",
    "                image = TF.vflip(image)\n",
    "\n",
    "        if self.rotation:\n",
    "            angle = random.uniform(-self.max_angle, self.max_angle)\n",
    "            \n",
    "            # Compute padding\n",
    "            _, h, w = image.shape\n",
    "            pad_r = self.pad_margin + pad_ratio(angle)\n",
    "            pad_h = int(pad_r * h)\n",
    "            pad_w = int(pad_r * w)\n",
    "\n",
    "            # Reflect padded image\n",
    "            image = F.pad(image, (pad_w, pad_w, pad_h, pad_h), mode='reflect')\n",
    "\n",
    "            # Rotate\n",
    "            image = TF.rotate(image, angle, interpolation=InterpolationMode.BILINEAR, fill=None)\n",
    "\n",
    "            # Center crop back to original size\n",
    "            image = TF.center_crop(image, (h, w))\n",
    "\n",
    "        return image\n",
    "\n",
    "    @staticmethod\n",
    "    pad_ratio = lambda x: (sqrt(2)/2) * cos(x % 90) * sqrt((1 - cos(x % 90))/(1 - cos(90 + (x % 90))))\n",
    "\n",
    "class LensDataset(Dataset):\n",
    "    def __init__(self, X, y, augmentor=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.augmentor = augmentor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.X[idx]\n",
    "        label = self.y[idx]\n",
    "\n",
    "        if self.augmentor:\n",
    "            image = self.augmentor(image)\n",
    "\n",
    "        return image, torch.tensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62667a00-50e6-4619-be44-043bcd56b2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = LensDataset(xtrain, ytrain, augmentor=ReflectiveAugmentor())\n",
    "val_dataset = LensDataset(xval, yval)\n",
    "\n",
    "batch_size = 1024\n",
    "\n",
    "seed = 42\n",
    "generator = torch.Generator()\n",
    "generator.manual_seed(seed)\n",
    "def worker_seed_func(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "def make_shuffled_dataloader(dataset, seed, epoch):\n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(seed + epoch)\n",
    "    return DataLoader(\n",
    "        dataset = dataset,\n",
    "        batch_size = batch_size,\n",
    "        shuffle = True,\n",
    "        generator = g,\n",
    "        num_workers = 4,\n",
    "        pin_memory = True,\n",
    "        drop_last = True,\n",
    "        worker_init_fn = worker_seed_func,\n",
    "    )\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataset = train_dataset, \n",
    "    batch_size = batch_size,\n",
    "    num_workers = 4,\n",
    "    pin_memory = True,\n",
    "    drop_last = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0f26a5-d2bf-4d21-b7cc-c6459bee6c8e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd92c1ec-0c4a-4fdc-a311-78c8c0fda7a9",
   "metadata": {},
   "source": [
    "##### Create CSV training log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c8e605-4765-4bf3-b436-162d86d7e090",
   "metadata": {},
   "outputs": [],
   "source": [
    "### To resume training, set epoch to last save epoch and set LR to last known LR.\n",
    "START_EPOCH = 0\n",
    "lr_stopped_at = 0.0\n",
    "\n",
    "run_name = \"F1\"\n",
    "today = date.today()\n",
    "d1 = today.strftime(\"%d_%m_%Y\") \n",
    "# this WILL override multiple runs on same day because of line 17, \n",
    "# rename run name to distinguish between runs on the same day\n",
    "\n",
    "parent_dir = \"_Time_Trials\"\n",
    "save_dir = parent_dir + \"/\" + d1 + run_name\n",
    "\n",
    "if START_EPOCH == 0:\n",
    "    !mkdir {parent_dir}\n",
    "    !rm -rf {save_dir}\n",
    "    !mkdir {save_dir}\n",
    "    print(\"CREATED DIRECTORY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64167b3-6ad4-435f-ae95-0cb450e3995b",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file = f\"{save_dir}/training_log.csv\"\n",
    "log_fields = [\"epoch\", \"train_loss\", \"train_auc\", \"train_precision\", \"train_recall\", \"val_loss\", \"val_auc\", \"val_precision\", \"val_recall\"]\n",
    "\n",
    "# Initialize CSV\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "with open(log_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(log_fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b34aee7-9deb-4dcb-9468-5ca6970f86b7",
   "metadata": {},
   "source": [
    "##### Model Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b128a62c-c68b-4478-b878-e30de24fed83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxViTClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=1, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model('maxvit_small_256', pretrained=pretrained, features_only=False)\n",
    "        \n",
    "        # Replace last layer with a binary classifier head\n",
    "        self.backbone.head = nn.Sequential(\n",
    "            nn.BatchNorm1d(self.backbone.num_features),\n",
    "            nn.Linear(self.backbone.num_features, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, num_classes),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c8acc8-8879-414b-841e-51b5fa675ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_metric = torchmetrics.AUROC(pos_label=1).to(device)\n",
    "precision_metric = torchmetrics.Precision(threshold=0.9).to(device)\n",
    "recall_metric = torchmetrics.Recall(threshold=0.9).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4918a5b-b01d-4eb5-a61c-b37b920762e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for x_batch, y_batch in dataloader:\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device).float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x_batch).squeeze()\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * x_batch.size(0)\n",
    "\n",
    "        auc_metric.update(outputs, y_batch.int())\n",
    "        precision_metric.update(outputs, y_batch.int())\n",
    "        recall_metric.update(outputs, y_batch.int())\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_auc = auc_metric.compute().item()\n",
    "    epoch_precision = precision_metric.compute().item()\n",
    "    epoch_recall = recall_metric.compute().item()\n",
    "\n",
    "    auc_metric.reset()\n",
    "    precision_metric.reset()\n",
    "    recall_metric.reset()\n",
    "\n",
    "    return epoch_loss, epoch_auc, epoch_precision, epoch_recall\n",
    "\n",
    "\n",
    "def validate_epoch(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in dataloader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device).float()\n",
    "            outputs = model(x_batch).squeeze()\n",
    "            loss = criterion(outputs, y_batch)\n",
    "\n",
    "            running_loss += loss.item() * x_batch.size(0)\n",
    "\n",
    "            auc_metric.update(outputs, y_batch.int())\n",
    "            precision_metric.update(outputs, y_batch.int())\n",
    "            recall_metric.update(outputs, y_batch.int())\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_auc = auc_metric.compute().item()\n",
    "    epoch_precision = precision_metric.compute().item()\n",
    "    epoch_recall = recall_metric.compute().item()\n",
    "\n",
    "    auc_metric.reset()\n",
    "    precision_metric.reset()\n",
    "    recall_metric.reset()\n",
    "\n",
    "    return epoch_loss, epoch_auc, epoch_precision, epoch_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d17753-fb3a-4770-aae8-e42aa6571ca5",
   "metadata": {},
   "source": [
    "##### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092021a9-8bfb-40ae-8356-8bea696585bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = MaxViTClassifier()\n",
    "model = torch.nn.DataParallel(model)\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "num_epochs = 160\n",
    "best_epoch = None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_auc, train_prec, train_rec = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss, val_auc, val_prec, val_rec = validate_epoch(model, val_loader, criterion, device)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Train | loss: {train_loss:.4f} AUC: {train_auc:.4f} Prec: {train_prec:.4f} Rec: {train_rec:.4f}\")\n",
    "    print(f\"Val   | loss: {val_loss:.4f} AUC: {val_auc:.4f} Prec: {val_prec:.4f} Rec: {val_rec:.4f}\")\n",
    "    if (best_epoch == None || val_auc >= best_epoch[1]):\n",
    "        best_epoch = (epoch, val_auc)\n",
    "        torch.save(model.state_dict(), f\"{save_dir}/chkpt_epoch_{epoch}.pt\")\n",
    "        print(f\"val_auc of {val_auc:.4f} beat previous best {best_epoch[1]:.4f}. Checkpoint Saved.\")\n",
    "        best_epoch = (epoch, val_auc)\n",
    "    print(\"--------\")\n",
    "        \n",
    "    with open(log_file, mode='a', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\n",
    "        epoch + 1,\n",
    "        train_loss,\n",
    "        train_auc,\n",
    "        train_prec,\n",
    "        train_rec,\n",
    "        val_loss,\n",
    "        val_auc,\n",
    "        val_prec,\n",
    "        val_rec,\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61aa108-a52b-49ad-9d3d-d2a54bf56629",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"{save_dir}/endrun.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-2.6.0",
   "language": "python",
   "name": "pytorch-2.6.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
