{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the MaxViTSmall Model for Lens Finding\n",
    "\n",
    "* You will need to install tensorflow_addons and keras-cv the first time you run this nb, as it is not in the tensorflow-2.9.0 kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow_addons\n",
    "# !pip install keras-cv-attention-models>=1.3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-07 13:43:01.892871: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-07-07 13:43:01.892914: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-07 13:43:01.937823: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-07 13:43:02.034734: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-07 13:43:05.732335: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPUs will likely run quickly with dtype policy mixed_float16 as they all have compute capability of at least 7.0\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.applications import EfficientNetV2S\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, BatchNormalization as BatchNorm\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import layers, Model, Input\n",
    "import keras_cv_attention_models\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import tensorflow_addons as tfa\n",
    "from datetime import date\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jul  7 13:43:22 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.163.01             Driver Version: 550.163.01     CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A100-SXM4-40GB          On  |   00000000:03:00.0 Off |                    0 |\n",
      "| N/A   31C    P0             57W /  400W |       5MiB /  40960MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA A100-SXM4-40GB          On  |   00000000:41:00.0 Off |                    0 |\n",
      "| N/A   29C    P0             53W /  400W |       5MiB /  40960MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   2  NVIDIA A100-SXM4-40GB          On  |   00000000:82:00.0 Off |                    0 |\n",
      "| N/A   31C    P0             54W /  400W |       5MiB /  40960MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   3  NVIDIA A100-SXM4-40GB          On  |   00000000:C1:00.0 Off |                    0 |\n",
      "| N/A   29C    P0             57W /  400W |       5MiB /  40960MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi \n",
    "\n",
    "# Run the following in a terminal to monitor VRAM during training\n",
    "# watch -n 0.5 nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clean_deluxe = '/global/cfs/projectdirs/cosmo/work/users/xhuang/dr10_1/Clean-Samples/TS40_deluxe_clean'\n",
    "ethan_sim_jwst = '/global/cfs/projectdirs/deepsrch/jwst_sims/pristine_bright/'\n",
    "data_path = clean_deluxe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * clean deluxe is our highest quality sample, in the Clean-Samples dir you will find TS40 Baseline, which has more samples, but some positive and negative candidates may not be as clear, or have additional noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ethan_sim_jwst\n",
    "\n",
    "x0 = np.load(path+\"images.npy\")\n",
    "y0 = np.load(path+\"lensed.npy\")\n",
    "cap = np.percentile(x0, 99)\n",
    "\n",
    "#Image pre-processing\n",
    "for i in range(len(x0)):\n",
    "    cap = np.percentile(x0[i],99)\n",
    "    x0[i][x0[i]>cap]=cap\n",
    "    x0[i] = (x0[i]-np.mean(x0[i])) / np.std(x0[i])\n",
    "# for i in range(len(x0)):\n",
    "#     x0[i] = x0[i] + add_poisson(x0[i], uniform.rvs(loc=150,scale=550))\n",
    "\n",
    "#train-val split\n",
    "np.random.seed(15)\n",
    "indices = np.arange(len(x0))\n",
    "np.random.shuffle(indices)\n",
    "start = len(x0)//5 * 0 #0\n",
    "end = len(x0)//5 * 1 #1\n",
    "val_inds = indices[start:end]\n",
    "train_inds = np.concatenate([indices[:start],indices[end:]])\n",
    "\n",
    "xtrain = x0[train_inds]\n",
    "xval = x0[val_inds]\n",
    "ytrain = y0[train_inds]\n",
    "yval = y0[val_inds]\n",
    "\n",
    "xtrain = np.reshape(xtrain,(len(xtrain),125,125,1))\n",
    "xval =  np.reshape(xval, (len(xval),125,125,1))\n",
    "ytrain = np.reshape(ytrain, (len(ytrain),1))\n",
    "yval =  np.reshape(yval, (len(yval),1))\n",
    "\n",
    "xtrain = np.clip(xtrain, -1, 1)  \n",
    "xval = np.clip(xval, -1, 1)\n",
    "\n",
    "if xtrain.ndim == 3:\n",
    "    xtrain = np.expand_dims(xtrain, axis=-1)\n",
    "if xval.ndim == 3:\n",
    "    xval = np.expand_dims(xval, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain type: <class 'numpy.ndarray'>\n",
      "xtrain shape: (94887, 101, 101, 3)\n",
      "xtrain dtype: float32\n",
      "ytrain type: <class 'numpy.ndarray'>\n",
      "ytrain shape: (94887, 1)\n",
      "ytrain dtype: float64\n",
      "Sample xtrain[0] shape: (101, 101, 3)\n",
      "Sample ytrain[0]: [0.]\n"
     ]
    }
   ],
   "source": [
    "data_path = clean_deluxe\n",
    "\n",
    "xtrain = np.load(f\"{data_path}/train_x.npy\")\n",
    "ytrain = np.load(f\"{data_path}/train_y.npy\").reshape(-1, 1)\n",
    "\n",
    "xval = np.load(f\"{data_path}/val_x.npy\")\n",
    "yval = np.load(f\"{data_path}/val_y.npy\").reshape(-1, 1)\n",
    "\n",
    "xtrain = np.clip(xtrain, -1, 1)  \n",
    "xval = np.clip(xval, -1, 1)\n",
    "\n",
    "if xtrain.ndim == 3:\n",
    "    xtrain = np.expand_dims(xtrain, axis=-1)\n",
    "if xval.ndim == 3:\n",
    "    xval = np.expand_dims(xval, axis=-1)\n",
    "\n",
    "print(\"xtrain type:\", type(xtrain))\n",
    "print(\"xtrain shape:\", getattr(xtrain, 'shape', 'No shape'))\n",
    "print(\"xtrain dtype:\", getattr(xtrain, 'dtype', 'No dtype'))\n",
    "\n",
    "print(\"ytrain type:\", type(ytrain))\n",
    "print(\"ytrain shape:\", getattr(ytrain, 'shape', 'No shape'))\n",
    "print(\"ytrain dtype:\", getattr(ytrain, 'dtype', 'No dtype'))\n",
    "\n",
    "# Check a single sample\n",
    "try:\n",
    "    print(\"Sample xtrain[0] shape:\", xtrain[0].shape)\n",
    "    print(\"Sample ytrain[0]:\", ytrain[0])\n",
    "except Exception as e:\n",
    "    print(\"Error accessing sample:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-07 13:43:48.437174: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:236] Using CUDA malloc Async allocator for GPU: 0\n",
      "2025-07-07 13:43:48.439508: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38366 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:03:00.0, compute capability: 8.0\n",
      "2025-07-07 13:43:48.440557: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:236] Using CUDA malloc Async allocator for GPU: 1\n",
      "2025-07-07 13:43:48.442096: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 38366 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:41:00.0, compute capability: 8.0\n",
      "2025-07-07 13:43:48.442359: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:236] Using CUDA malloc Async allocator for GPU: 2\n",
      "2025-07-07 13:43:48.443724: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 38366 MB memory:  -> device: 2, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:82:00.0, compute capability: 8.0\n",
      "2025-07-07 13:43:48.444006: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:236] Using CUDA malloc Async allocator for GPU: 3\n",
      "2025-07-07 13:43:48.445338: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 38366 MB memory:  -> device: 3, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:c1:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    def ensure_rgb(x):\n",
    "        if x.shape.rank == 3 and x.shape[-1] == 1:\n",
    "            x = tf.image.grayscale_to_rgb(x)\n",
    "        return x\n",
    "    def preprocess(x, y):\n",
    "        x = ensure_rgb(x)\n",
    "        x = tf.image.resize(x, [224, 224])\n",
    "        x = tf.image.random_flip_left_right(tf.image.random_flip_up_down(x))\n",
    "        rg = tf.random.uniform(shape=[],minval=0, maxval=2 * np.pi, dtype=tf.float32)\n",
    "        x = tfa.image.rotate(x, angles=rg, fill_mode = 'reflect')\n",
    "        return x, y\n",
    "    def preprocess_val(x, y):\n",
    "        x = ensure_rgb(x)\n",
    "        x = tf.image.resize(x, [224, 224])\n",
    "        return x, y\n",
    "    # image augmentation to help prevent overfitting in training. \n",
    "\n",
    "    options = tf.data.Options()\n",
    "    options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.AUTO\n",
    "    \n",
    "    batch_size = 512\n",
    "    train = (tf.data.Dataset.from_tensor_slices((xtrain, ytrain))\n",
    "            .map(preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "            .shuffle(len(ytrain), reshuffle_each_iteration=True, seed=42) \n",
    "            .repeat()\n",
    "            .batch(batch_size)\n",
    "            .prefetch(tf.data.experimental.AUTOTUNE)).with_options(options)\n",
    "    \n",
    "    validate = (tf.data.Dataset.from_tensor_slices((xval, yval))\n",
    "            .map(preprocess_val, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "            .shuffle(len(yval))\n",
    "            .repeat()\n",
    "            .batch(batch_size)\n",
    "            .prefetch(tf.data.experimental.AUTOTUNE)).with_options(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘_Time_Trials’: File exists\n",
      "CREATED DIRECTORY\n"
     ]
    }
   ],
   "source": [
    "### To resume training, set epoch to last save epoch and set LR to last known LR.\n",
    "START_EPOCH = 0\n",
    "lr_stopped_at = 0.0\n",
    "\n",
    "run_name = \"F1\"\n",
    "today = date.today()\n",
    "d1 = today.strftime(\"%d_%m_%Y\") \n",
    "# this WILL override multiple runs on same day because of line 17, \n",
    "# rename run name to distinguish between runs on the same day\n",
    "\n",
    "parent_dir = \"_Time_Trials\"\n",
    "save_dir = parent_dir + \"/\" + d1 + run_name\n",
    "\n",
    "if START_EPOCH == 0:\n",
    "    !mkdir {parent_dir}\n",
    "    !rm -rf {save_dir}\n",
    "    !mkdir {save_dir}\n",
    "    print(\"CREATED DIRECTORY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=8,\n",
    "    verbose=1,\n",
    "    min_lr=1e-7\n",
    ")\n",
    "\n",
    "metrics = tf.keras.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy(cross_device_ops = tf.distribute.ReductionToOneDevice())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_maxvit(lr=1e-5):\n",
    "    inputlayer = Input(shape = (224,224,3))\n",
    "    base_model = keras_cv_attention_models.maxvit.MaxViT_Tiny(pretrained='imagenet', pretrained_base=True)\n",
    "    base_model.trainable = True\n",
    "    headless_output = Model(inputs=base_model.input, outputs=base_model.layers[-2].output) # required since head is 1000 logit classifier\n",
    "    \n",
    "    x = headless_output(inputlayer)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    output = Dense(1, activation='sigmoid', dtype='float32')(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inputlayer, outputs=output)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate = lr),\n",
    "        loss = tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "        metrics = [\n",
    "            metrics.AUC(num_thresholds=1000), \n",
    "            metrics.Precision(0.9), \n",
    "            metrics.Recall(0.9),\n",
    "        ],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    f\"{save_dir}/chkpt.h5\", \n",
    "    monitor = f'val_auc', \n",
    "    save_best_only = True, \n",
    "    mode = 'max', \n",
    "    verbose = 1, \n",
    "    save_weights_only = True,\n",
    ")\n",
    "\n",
    "csv_logger = CSVLogger(\n",
    "    f\"{save_dir}/training_history.csv\", \n",
    "    separator = ',', \n",
    "    append = True,\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    checkpoint, \n",
    "    csv_logger,\n",
    "    reduce_lr,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      ">>>> Load pretrained from: /global/homes/a/amurr1/.keras/models/maxvit_tiny_224_imagenet.h5\n",
      "Number of devices: 4\n",
      "Start: 1750306627.7158923\n",
      "Epoch 1/160\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-18 21:20:24.404471: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] fused(ShuffleDatasetV3:2,RepeatDataset:3): Filling up shuffle buffer (this may take a while): 70900 of 94887\n",
      "2025-06-18 21:20:26.892476: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:452] Shuffle buffer filled.\n",
      "2025-06-18 21:20:28.062270: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8903\n",
      "2025-06-18 21:20:28.062371: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8903\n",
      "2025-06-18 21:20:28.075060: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8903\n",
      "2025-06-18 21:20:28.086737: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - ETA: 0s - loss: 0.5205 - auc: 0.4272 - precision: 0.0000e+00 - recall: 0.0000e+00      \n",
      "Epoch 1: val_auc improved from -inf to 0.51548, saving model to _Time_Trials/18_06_2025F1/chkpt.h5\n",
      "185/185 [==============================] - 434s 1s/step - loss: 0.5205 - auc: 0.4272 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6350 - val_auc: 0.5155 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-05\n",
      "Epoch 2/160\n",
      "185/185 [==============================] - ETA: 0s - loss: 0.5202 - auc: 0.4324 - precision: 0.0000e+00 - recall: 0.0000e+00  \n",
      "Epoch 2: val_auc did not improve from 0.51548\n",
      "185/185 [==============================] - 174s 938ms/step - loss: 0.5202 - auc: 0.4324 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5920 - val_auc: 0.4595 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-05\n",
      "Epoch 3/160\n",
      "185/185 [==============================] - ETA: 0s - loss: 0.5203 - auc: 0.4373 - precision: 0.0000e+00 - recall: 0.0000e+00  \n",
      "Epoch 3: val_auc did not improve from 0.51548\n",
      "185/185 [==============================] - 169s 915ms/step - loss: 0.5203 - auc: 0.4373 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5370 - val_auc: 0.4899 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-05\n",
      "Epoch 4/160\n",
      "185/185 [==============================] - ETA: 0s - loss: 0.5200 - auc: 0.4386 - precision: 0.0000e+00 - recall: 0.0000e+00  \n",
      "Epoch 4: val_auc did not improve from 0.51548\n",
      "185/185 [==============================] - 172s 927ms/step - loss: 0.5200 - auc: 0.4386 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5070 - val_auc: 0.4989 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-05\n",
      "Epoch 5/160\n",
      "185/185 [==============================] - ETA: 0s - loss: 0.5204 - auc: 0.4459 - precision: 0.0000e+00 - recall: 0.0000e+00 0\n",
      "Epoch 5: val_auc did not improve from 0.51548\n",
      "185/185 [==============================] - 162s 875ms/step - loss: 0.5204 - auc: 0.4459 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5014 - val_auc: 0.5020 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-05\n",
      "Epoch 6/160\n",
      "185/185 [==============================] - ETA: 0s - loss: 0.5201 - auc: 0.4305 - precision: 0.0000e+00 - recall: 0.0000e+00  \n",
      "Epoch 6: val_auc did not improve from 0.51548\n",
      "185/185 [==============================] - 158s 856ms/step - loss: 0.5201 - auc: 0.4305 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5004 - val_auc: 0.5001 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-05\n",
      "Epoch 7/160\n",
      "185/185 [==============================] - ETA: 0s - loss: 0.5202 - auc: 0.4289 - precision: 0.0000e+00 - recall: 0.0000e+00  \n",
      "Epoch 7: val_auc did not improve from 0.51548\n",
      "185/185 [==============================] - 155s 841ms/step - loss: 0.5202 - auc: 0.4289 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5005 - val_auc: 0.5007 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-05\n",
      "Epoch 8/160\n",
      "185/185 [==============================] - ETA: 0s - loss: 0.5198 - auc: 0.4309 - precision: 0.0000e+00 - recall: 0.0000e+00  \n",
      "Epoch 8: val_auc did not improve from 0.51548\n",
      "185/185 [==============================] - 160s 863ms/step - loss: 0.5198 - auc: 0.4309 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5004 - val_auc: 0.5010 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-05\n",
      "Epoch 9/160\n",
      "185/185 [==============================] - ETA: 0s - loss: 0.5200 - auc: 0.4312 - precision: 0.0000e+00 - recall: 0.0000e+00  \n",
      "Epoch 9: val_auc did not improve from 0.51548\n",
      "185/185 [==============================] - 159s 860ms/step - loss: 0.5200 - auc: 0.4312 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5006 - val_auc: 0.5017 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-05\n",
      "Epoch 10/160\n",
      "185/185 [==============================] - ETA: 0s - loss: 0.5200 - auc: 0.4238 - precision: 0.0000e+00 - recall: 0.0000e+00  \n",
      "Epoch 10: val_auc did not improve from 0.51548\n",
      "185/185 [==============================] - 158s 853ms/step - loss: 0.5200 - auc: 0.4238 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5007 - val_auc: 0.4995 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-05\n",
      "Epoch 11/160\n",
      "185/185 [==============================] - ETA: 0s - loss: 0.5197 - auc: 0.4324 - precision: 0.0000e+00 - recall: 0.0000e+00  \n",
      "Epoch 11: val_auc did not improve from 0.51548\n",
      "185/185 [==============================] - 159s 858ms/step - loss: 0.5197 - auc: 0.4324 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5008 - val_auc: 0.5014 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-05\n",
      "Epoch 12/160\n",
      "185/185 [==============================] - ETA: 0s - loss: 0.5199 - auc: 0.4326 - precision: 0.0000e+00 - recall: 0.0000e+00  \n",
      "Epoch 12: val_auc did not improve from 0.51548\n",
      "185/185 [==============================] - 155s 839ms/step - loss: 0.5199 - auc: 0.4326 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5006 - val_auc: 0.5006 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-05\n",
      "Epoch 13/160\n",
      "185/185 [==============================] - ETA: 0s - loss: 0.5201 - auc: 0.4446 - precision: 0.0000e+00 - recall: 0.0000e+00  \n",
      "Epoch 13: val_auc did not improve from 0.51548\n",
      "185/185 [==============================] - 163s 880ms/step - loss: 0.5201 - auc: 0.4446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5007 - val_auc: 0.5019 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-05\n",
      "Epoch 14/160\n",
      "185/185 [==============================] - ETA: 0s - loss: 0.5200 - auc: 0.4349 - precision: 0.0000e+00 - recall: 0.0000e+00  \n",
      "Epoch 14: val_auc did not improve from 0.51548\n",
      "185/185 [==============================] - 155s 836ms/step - loss: 0.5200 - auc: 0.4349 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5003 - val_auc: 0.5033 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-05\n",
      "Epoch 15/160\n",
      "185/185 [==============================] - ETA: 0s - loss: 0.5199 - auc: 0.4321 - precision: 0.0000e+00 - recall: 0.0000e+00  \n",
      "Epoch 15: val_auc did not improve from 0.51548\n",
      "185/185 [==============================] - 159s 859ms/step - loss: 0.5199 - auc: 0.4321 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5006 - val_auc: 0.5017 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-05\n",
      "Epoch 16/160\n",
      "185/185 [==============================] - ETA: 0s - loss: 0.5203 - auc: 0.4346 - precision: 0.0000e+00 - recall: 0.0000e+00  \n",
      "Epoch 16: val_auc did not improve from 0.51548\n",
      "185/185 [==============================] - 161s 870ms/step - loss: 0.5203 - auc: 0.4346 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.5000 - val_auc: 0.5004 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-05\n",
      "Epoch 17/160\n",
      " 34/185 [====>.........................] - ETA: 1:44 - loss: 0.5218 - auc: 0.4806 - precision: 0.0000e+00 - recall: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    \n",
    "    train_dist = strategy.experimental_distribute_dataset(train)\n",
    "    val_dist = strategy.experimental_distribute_dataset(validate)\n",
    "\n",
    "    ### Distributed Training ###\n",
    "    \n",
    "    model = create_maxvit()\n",
    "\n",
    "    print(\"Number of devices: {}\".format(strategy.num_replicas_in_sync))\n",
    "    start = time.time()\n",
    "    print(f'Start: {start}')\n",
    "    \n",
    "    model.fit(\n",
    "        train_dist, \n",
    "        validation_data = val_dist, \n",
    "        epochs = 160, \n",
    "        steps_per_epoch = (len(ytrain) // batch_size), \n",
    "        callbacks = callbacks, \n",
    "        verbose = 1, \n",
    "        batch_size = batch_size, \n",
    "        validation_steps = (len(yval) // batch_size),\n",
    "    )\n",
    "    \n",
    "    end = time.time()\n",
    "    print(f'Total time running: {end-start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save_weights(f'{save_dir}/endrun.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_results = f\"{save_dir}/training_history.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metric = \"\"\n",
    "df = pd.read_csv(path_results)\n",
    "val_auc_max = max(df[\"val_auc\" + metric])\n",
    "auc_max = max(df[\"auc\" + metric])\n",
    "largest = [max(df[\"val_auc\" + metric][:i+1]) for i in range(len(df))]\n",
    "plt.plot(df[\"auc\" + metric],label='Peak train = {:.5f}'.format(auc_max))\n",
    "plt.plot(df[\"val_auc\" + metric], label='Peak val = {:.5f}'.format(val_auc_max))\n",
    "plt.plot(largest, label='max')\n",
    "plt.legend()\n",
    "plt.ylim(0.95,1)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# print(f\"Max train AUC: {auc_max:.5f}, Max val AUC: {val_auc_max:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_loss = min(df[\"val_loss\"])\n",
    "train_loss = min(df[\"loss\"])\n",
    "plt.plot(df[\"loss\"],label=f'Train loss: {train_loss:.4f}')\n",
    "plt.plot(df[\"val_loss\"], label=f'Val loss: {val_loss:.4f}')\n",
    "plt.ylim(top=0.1, bottom=0)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endrun_preds = model.predict(xval)\n",
    "model.load_weights(f'{save_dir}/chkpt.h5')\n",
    "best_preds = model.predict(xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(yval, endrun_preds)\n",
    "auc_roc = roc_auc_score(yval, endrun_preds)\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 12))\n",
    "\n",
    "axs[0,0].plot(fpr, tpr, label='Effnet (area = {:.5f})'.format(auc_roc))\n",
    "axs[0,0].set_xlabel('False positive rate')\n",
    "axs[0,0].set_ylabel('True positive rate')\n",
    "axs[0,0].set_title('Endrun ROC curve')\n",
    "axs[0,0].legend(loc='best')\n",
    "\n",
    "axs[0,1].set_xlim(0, 0.2)\n",
    "axs[0,1].set_ylim(0.8, 1)\n",
    "axs[0,1].plot(fpr, tpr, label='Effnet (area = {:.5f})'.format(auc_roc))\n",
    "axs[0,1].set_xlabel('False positive rate')\n",
    "axs[0,1].set_ylabel('True positive rate')\n",
    "axs[0,1].set_title('Endrun ROC curve (zoomed in at top left)')\n",
    "axs[0,1].legend(loc='best')\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(yval, best_preds)\n",
    "auc_roc2 = roc_auc_score(yval, best_preds)\n",
    "\n",
    "axs[1,0].plot(fpr, tpr, label='Effnet (area = {:.5f})'.format(auc_roc2))\n",
    "axs[1,0].set_xlabel('False positive rate')\n",
    "axs[1,0].set_ylabel('True positive rate')\n",
    "axs[1,0].set_title('Best val_auc ROC curve')\n",
    "axs[1,0].legend(loc='best')\n",
    "\n",
    "axs[1,1].set_xlim(0, 0.2)\n",
    "axs[1,1].set_ylim(0.8, 1)\n",
    "axs[1,1].plot(fpr, tpr, label='Effnet (area = {:.5f})'.format(auc_roc2))\n",
    "axs[1,1].set_xlabel('False positive rate')\n",
    "axs[1,1].set_ylabel('True positive rate')\n",
    "axs[1,1].set_title('Best val_auc ROC curve (zoomed in at top left)')\n",
    "axs[1,1].legend(loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_dir = '/global/homes/b/bkauf/Clean_Training/0.999_f_deluxe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_results = f\"{save_dir}/training_history.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metric = \"\"\n",
    "df = pd.read_csv(path_results)\n",
    "val_auc_max = max(df[\"val_auc\" + metric])\n",
    "auc_max = max(df[\"auc\" + metric])\n",
    "largest = [max(df[\"val_auc\" + metric][:i+1]) for i in range(len(df))]\n",
    "plt.plot(df[\"auc\" + metric],label='Peak train = {:.5f}'.format(auc_max))\n",
    "plt.plot(df[\"val_auc\" + metric], label='Peak val = {:.5f}'.format(val_auc_max))\n",
    "plt.plot(largest, label='max')\n",
    "plt.legend()\n",
    "plt.ylim(0.95,1)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# print(f\"Max train AUC: {auc_max:.5f}, Max val AUC: {val_auc_max:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_loss = min(df[\"val_loss\"])\n",
    "train_loss = min(df[\"loss\"])\n",
    "plt.plot(df[\"loss\"],label=f'Train loss: {train_loss:.4f}')\n",
    "plt.plot(df[\"val_loss\"], label=f'Val loss: {val_loss:.4f}')\n",
    "plt.ylim(top=0.1, bottom=0)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endrun_preds = model.predict(xval)\n",
    "model.load_weights(f'{save_dir}/chkpt.h5')\n",
    "best_preds = model.predict(xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(yval, endrun_preds)\n",
    "auc_roc = roc_auc_score(yval, endrun_preds)\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 12))\n",
    "\n",
    "axs[0,0].plot(fpr, tpr, label='Effnet (area = {:.5f})'.format(auc_roc))\n",
    "axs[0,0].set_xlabel('False positive rate')\n",
    "axs[0,0].set_ylabel('True positive rate')\n",
    "axs[0,0].set_title('Endrun ROC curve')\n",
    "axs[0,0].legend(loc='best')\n",
    "\n",
    "axs[0,1].set_xlim(0, 0.2)\n",
    "axs[0,1].set_ylim(0.8, 1)\n",
    "axs[0,1].plot(fpr, tpr, label='Effnet (area = {:.5f})'.format(auc_roc))\n",
    "axs[0,1].set_xlabel('False positive rate')\n",
    "axs[0,1].set_ylabel('True positive rate')\n",
    "axs[0,1].set_title('Endrun ROC curve (zoomed in at top left)')\n",
    "axs[0,1].legend(loc='best')\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(yval, best_preds)\n",
    "auc_roc2 = roc_auc_score(yval, best_preds)\n",
    "\n",
    "axs[1,0].plot(fpr, tpr, label='Effnet (area = {:.5f})'.format(auc_roc2))\n",
    "axs[1,0].set_xlabel('False positive rate')\n",
    "axs[1,0].set_ylabel('True positive rate')\n",
    "axs[1,0].set_title('Best val_auc ROC curve')\n",
    "axs[1,0].legend(loc='best')\n",
    "\n",
    "axs[1,1].set_xlim(0, 0.2)\n",
    "axs[1,1].set_ylim(0.8, 1)\n",
    "axs[1,1].plot(fpr, tpr, label='Effnet (area = {:.5f})'.format(auc_roc2))\n",
    "axs[1,1].set_xlabel('False positive rate')\n",
    "axs[1,1].set_ylabel('True positive rate')\n",
    "axs[1,1].set_title('Best val_auc ROC curve (zoomed in at top left)')\n",
    "axs[1,1].legend(loc='best')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-2.15.0",
   "language": "python",
   "name": "tensorflow-2.15.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
